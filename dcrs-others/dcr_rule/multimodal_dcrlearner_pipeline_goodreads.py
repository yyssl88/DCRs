#!/usr/bin/env python3
# -*- coding: utf-8 -*-


import os
# è®¾ç½®åªä½¿ç”¨5å·GPUå¡
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

import sys
import json
import random
import pickle
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from transformers import AutoTokenizer, AutoModel, AutoProcessor
from PIL import Image
import torchvision.transforms as transforms
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
import warnings
warnings.filterwarnings('ignore')
import math
import re

# æ·»åŠ åˆ†å¸ƒå¼è®¡ç®—æ”¯æŒ
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
from functools import partial
import time
from typing import List, Tuple, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_dir))))
sys.path.insert(0, project_root)


class MultimodalModels:
    """å¤šæ¨¡æ€æ¨¡å‹é›†åˆ - External Models Mğ‘ˆ"""
    
    def __init__(self, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self._init_models()
    
    def _init_models(self):
        """åˆå§‹åŒ–å¤šæ¨¡æ€æ¨¡å‹"""
        print("ğŸ”§ Initializing Multimodal Models Mğ‘ˆ...")
        
        # æ–‡æ¡£ç±»æ¨¡å‹
        self.bert_mrc = self._create_bert_mrc()
        
        # å¤šæ¨¡æ€æ¨¡å‹
        self.qwen_vl = self._create_qwen_vl()

        
        print("âœ… Multimodal Models Mğ‘ˆ initialized")
    
    def _create_bert_mrc(self):
        """åˆ›å»ºBert-MRC [43] - å®ä½“æå–æ¨¡å‹ï¼Œä½¿ç”¨BGE-M3"""
        # ä½¿ç”¨æœ¬åœ°BGE-M3æ¨¡å‹
        model_path = "/data_nas/model_hub/bge-m3"
        
        print(f"ğŸ“ Loading BGE-M3 from local path: {model_path}")
        self.bert_tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
        self.bert_model = AutoModel.from_pretrained(model_path, local_files_only=True)
        self.bert_model.to(self.device)
        self.bert_model.eval()
        print("âœ… BGE-M3 [43] initialized")
        return True
    

    
    def _create_qwen_vl(self):
        """åˆ›å»ºQwen-2.5-VL [73] - å›¾åƒ/è§†é¢‘å¤„ç†æ¨¡å‹ï¼Œä½¿ç”¨Qwen2.5-VL-7B-Instruct"""
        # ä½¿ç”¨æœ¬åœ°Qwen2.5-VL-7B-Instructæ¨¡å‹
        model_path = "/data_nas/model_hub/Qwen2.5-VL-7B-Instruct"
        
        print(f"ğŸ“ Loading Qwen2.5-VL-7B-Instruct from local path: {model_path}")
        self.qwen_processor = AutoProcessor.from_pretrained(model_path, local_files_only=True)
        
        # åŠ è½½æ”¯æŒç”Ÿæˆçš„æ¨¡å‹ç±»
        from transformers import Qwen2_5_VLForConditionalGeneration
        self.qwen_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(model_path, local_files_only=True)
        self.qwen_model.to(self.device)
        self.qwen_model.eval()
        print("âœ… Qwen2.5-VL-7B-Instruct [73] initialized (with generation support)")
        return True
    
    def _load_and_preprocess_image(self, image_path):
        """åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ"""
        try:
            from PIL import Image
            import torchvision.transforms as transforms
            
            # åŠ è½½å›¾åƒ
            image = Image.open(image_path).convert('RGB')
            
            # å®šä¹‰é¢„å¤„ç†å˜æ¢
            transform = transforms.Compose([
                transforms.Resize((224, 224)),  # è°ƒæ•´å¤§å°
                transforms.ToTensor(),  # è½¬æ¢ä¸ºå¼ é‡
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # æ ‡å‡†åŒ–
            ])
            
            # åº”ç”¨å˜æ¢
            image_tensor = transform(image)
            
            return image_tensor
            
        except Exception as e:
            print(f"âŒ Error loading image {image_path}: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„å›¾åƒå¼ é‡
            return torch.zeros(3, 224, 224)
    
    def extract_image_features(self, image_path):
        """ä»…æå–å›¾åƒç‰¹å¾embeddingï¼Œä¿ç•™åŸå§‹ç»´åº¦"""
        if not os.path.exists(image_path):
            print(f"âŒ Image file not found: {image_path}")
            return None
        try:
            from PIL import Image
            image = Image.open(image_path).convert('RGB')
            print(f"âœ… Loaded image: {image.size}")
            with torch.no_grad():
                prompt = "Describe this image."
                inputs = self.qwen_processor(
                    text=prompt,
                    images=image, 
                    return_tensors="pt"
                )
                if 'pixel_values' in inputs:
                    inputs['images'] = inputs.pop('pixel_values')
                model_inputs = {}
                for key in ['input_ids', 'attention_mask', 'pixel_values']:
                    if key in inputs:
                        model_inputs[key] = inputs[key]
                model_inputs = {k: v.to(self.device) for k, v in model_inputs.items()}
                outputs = self.qwen_model(**model_inputs)
                if hasattr(outputs, 'image_embeds'):
                    img_feat = outputs.image_embeds
                elif hasattr(outputs, 'last_hidden_state'):
                    img_feat = outputs.last_hidden_state[:, 0, :]
                elif hasattr(outputs, 'logits'):
                    img_feat = outputs.logits.mean(dim=1)
                else:
                    img_feat = torch.zeros(1, 1).to(self.device)
                return img_feat
        except Exception as e:
            print(f"âŒ Error extracting image features from {image_path}: {e}")
            import traceback
            traceback.print_exc()
            return None

    def extract_image_category(self, image_path):
        """ä»…è¯†åˆ«å›¾åƒç±»åˆ«æˆ–æ‰€å±label"""
        if not os.path.exists(image_path):
            print(f"âŒ Image file not found: {image_path}")
            return None
        try:
            from PIL import Image
            image = Image.open(image_path).convert('RGB')
            print(f"âœ… Loaded image: {image.size}")
            with torch.no_grad():
                category_prompt = "è¯·è¯†åˆ«å›¾ç‰‡çš„ä¸»è¦ç±»åˆ«æˆ–æ ‡ç­¾"
                text_inputs = self.qwen_processor(
                    text=category_prompt,
                    images=image,
                    return_tensors="pt"
                )
                if 'pixel_values' in text_inputs:
                    text_inputs['images'] = text_inputs.pop('pixel_values')
                model_text_inputs = {}
                for key in ['input_ids', 'attention_mask', 'pixel_values']:
                    if key in text_inputs:
                        model_text_inputs[key] = text_inputs[key]
                model_text_inputs = {k: v.to(self.device) for k, v in model_text_inputs.items()}
                generated_ids = self.qwen_model.generate(
                    **model_text_inputs,
                    max_new_tokens=20,
                    do_sample=True,
                    temperature=0.3,
                    pad_token_id=self.qwen_processor.tokenizer.eos_token_id
                )
                category = self.qwen_processor.tokenizer.decode(generated_ids[0], skip_special_tokens=True)
                category = category.replace(category_prompt, "").strip()
                if not category or len(category) < 2:
                    category = "æœªçŸ¥ç±»åˆ«"
                return category
        except Exception as e:
            print(f"âŒ Error extracting image category from {image_path}: {e}")
            import traceback
            traceback.print_exc()
            return None

    
    def extract_text_features(self, text):
        """æå–å•ä¸ªæ–‡æœ¬çš„embeddingï¼Œä¿ç•™åŸå§‹ç»´åº¦"""
        if not text or not isinstance(text, str):
            return torch.zeros(1).to(self.device)
        inputs = self.bert_tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        with torch.no_grad():
            outputs = self.bert_model(**inputs)
            text_feat = outputs.last_hidden_state[:, 0, :]  # [1, hidden_size]
            return text_feat.squeeze(0)
    

class PredicateConstructor:
    def __init__(self, csv_path):
        self.df = pd.read_csv(csv_path)
        self.col_types = self._infer_col_types()
        self.row_ids = [f"t{i}" for i in range(len(self.df))]

    def _infer_col_types(self):
        col_types = {}
        for col in self.df.columns:
            if "img_path" in col:
                col_types[col] = "img_path"
            elif self.df[col].dtype in ['float64', 'int64']:
                col_types[col] = "numeric"
            elif self.df[col].dtype == 'object':
                unique_count = self.df[col].nunique()
                avg_len = self.df[col].astype(str).apply(len).mean()
                if unique_count < 20:
                    col_types[col] = "enum"
                elif avg_len > 20:
                    col_types[col] = "text"
                else:
                    col_types[col] = "enum"
            else:
                col_types[col] = "other"
        return col_types

    def construct_predicates(self):
        predicates = []
        for col, typ in self.col_types.items():
            if typ == "enum":
                try:
                    values = self.df[col].dropna().astype(str)
                    if len(values) == 0:
                        continue
                    # å¢åŠ è°“è¯å¤šæ ·æ€§ï¼Œä½†ä¿æŒç²¾ç¡®æ€§
                    top_modes = values.value_counts().index[:5]  # å¢åŠ æ›´å¤šä¼—æ•°
                    for val in top_modes:
                        predicates.append(f'{col} = "{val}"')

                except Exception as e:
                    print(f"âš ï¸ æšä¸¾å‹åˆ— {col} æ„é€ è°“è¯å‡ºé”™: {e}")
            elif typ == "numeric" and str(self.df[col].dtype).startswith("int"):
                try:
                    values = self.df[col].dropna().astype(int)
                    if len(values) == 0:
                        continue
                    mean_val = int(values.mean())
                    min_val = int(values.min())
                    max_val = int(values.max())
                    median_val = int(values.median())
                    q25_val = int(values.quantile(0.25))
                    q75_val = int(values.quantile(0.75))
                    for val in set([mean_val, min_val, max_val, median_val, q25_val, q75_val]):
                        predicates.append(f'{col} = {val}')
                        # predicates.append(f'{col} != {val}')  # æ³¨é‡Šæ‰ä¸ç­‰äºè°“è¯
                        predicates.append(f'{col} > {val}')   # æ³¨é‡Šæ‰å¤§äºè°“è¯
                        predicates.append(f'{col} < {val}')   # æ³¨é‡Šæ‰å°äºè°“è¯
                except Exception as e:
                    print(f"âš ï¸ intæ•°å€¼å‹åˆ— {col} æ„é€ è°“è¯å‡ºé”™: {e}")
            elif typ == "numeric" and str(self.df[col].dtype).startswith("float"):
                try:
                    values = self.df[col].dropna().astype(float)
                    if len(values) == 0:
                        continue
                    mean_val = float(values.mean())
                    min_val = float(values.min())
                    max_val = float(values.max())
                    median_val = float(values.median())
                    q25_val = float(values.quantile(0.25))
                    q75_val = float(values.quantile(0.75))
                    for val in [mean_val, min_val, max_val, median_val, q25_val, q75_val]:
                        predicates.append(f'{col} = {val}')  # é‡æ–°å¯ç”¨floatåˆ—çš„ = è°“è¯
                        predicates.append(f'{col} > {val}')   # æ³¨é‡Šæ‰å¤§äºè°“è¯
                        predicates.append(f'{col} < {val}')   # æ³¨é‡Šæ‰å°äºè°“è¯
                except Exception as e:
                    print(f"âš ï¸ floatæ•°å€¼å‹åˆ— {col} æ„é€ è°“è¯å‡ºé”™: {e}")
            # ä¸ºembeddingèšç±»åˆ—æ„é€ è°“è¯
            elif "embed_cluster" in col or "img_category" in col:
                try:
                    values = self.df[col].dropna()
                    if len(values) == 0:
                        continue
                    unique_vals = values.unique()
                    for val in unique_vals[:10]:  # é™åˆ¶æœ€å¤š10ä¸ªèšç±»
                        if pd.notna(val):
                            predicates.append(f'{col} = {val}')
                except Exception as e:
                    print(f"âš ï¸ èšç±»åˆ— {col} æ„é€ è°“è¯å‡ºé”™: {e}")
        return predicates


class MCTSNode:
    def __init__(self, predicates, parent=None):
        self.predicates = predicates  # å½“å‰èŠ‚ç‚¹çš„è°“è¯ç»„åˆï¼ˆlistï¼‰
        self.parent = parent
        self.children = []
        self.visits = 0
        self.value = 0.0

    def is_terminal(self, max_depth, all_predicates):
        return len(self.predicates) >= max_depth or len(set(all_predicates) - set(self.predicates)) == 0

    def expand(self, all_predicates):
        unused = list(set(all_predicates) - set(self.predicates))
        for p in unused:
            child = MCTSNode(self.predicates + [p], parent=self)
            self.children.append(child)
        return self.children

    def best_child(self, c_param=1.4):
        import numpy as np
        choices_weights = [
            (child.value / (child.visits + 1e-6)) + c_param * math.sqrt(math.log(self.visits + 1) / (child.visits + 1e-6))
            for child in self.children
        ]
        return self.children[np.argmax(choices_weights)]

# ä¿®æ”¹predicate_maskæ”¯æŒcol op valæ ¼å¼

def predicate_mask(df, pred):
    import re
    import numpy as np
    m = re.match(r'(\w+)\s*([=!<>]+)\s*(.+)', pred)
    if not m:
        return np.ones(len(df), dtype=bool)
    col, op, val = m.groups()
    val = val.strip('"')
    if col not in df.columns:
        return np.ones(len(df), dtype=bool)
    if op == '=':
        return df[col].astype(str) == val
    elif op == '!=':
        return df[col].astype(str) != val
    elif op == '>':
        return df[col].astype(float) > float(val)
    elif op == '<':
        return df[col].astype(float) < float(val)
    else:
        return np.ones(len(df), dtype=bool)

def evaluate_rule(df, predicates, target_col='y'):
    import numpy as np
    if not predicates or len(predicates) < 2:
        return 0, 0.0
    premise_preds = predicates[:-1]
    conclusion_pred = predicates[-1]
    # å‰æmask
    mask = np.ones(len(df), dtype=bool)
    for pred in premise_preds:
        mask = mask & predicate_mask(df, pred)
    support_count = mask.sum()
    support = support_count / len(df) if len(df) > 0 else 0
    if support_count == 0:
        return 0, 0.0
    # ç»“è®ºmask
    mask_conclusion = mask & predicate_mask(df, conclusion_pred)
    confidence = mask_conclusion.sum() / support_count
    return support, confidence


def mcts_rule_discovery(df, predicates, enum_predicates, max_depth=3, n_iter=100):
    results = []
    feature_predicates = [p for p in predicates if p not in enum_predicates]
    for y_pred in enum_predicates:
        root = MCTSNode([y_pred])
        best_support, best_confidence = 0, 0.0
        best_rule = []
        for _ in range(n_iter):
            node = root
            # Selection
            while node.children:
                node = node.best_child()
            # Expansion
            if not node.is_terminal(max_depth, feature_predicates):
                node.expand(feature_predicates)
                if node.children:
                    import random
                    node = random.choice(node.children)
            # Simulation
            sim_preds = list(node.predicates)
            unused = list(set(feature_predicates) - set(sim_preds[1:]))
            import random
            while len(sim_preds) < max_depth and unused:
                sim_preds.append(random.choice(unused))
                unused = list(set(feature_predicates) - set(sim_preds[1:]))
            # è¯„ä¼°ï¼šå‰æ=sim_preds[1:], ç»“è®º=sim_preds[0]
            support, confidence = evaluate_rule(df, [sim_preds[0]] + sim_preds[1:])
            reward = support * confidence
            tmp_node = node
            while tmp_node:
                tmp_node.visits += 1
                tmp_node.value += reward
                tmp_node = tmp_node.parent
            if reward > best_support * best_confidence:
                best_support, best_confidence = support, confidence
                best_rule = list(sim_preds)
        results.append((y_pred, best_rule, best_support, best_confidence))
    return results


def mcts_rule_discovery_single_y_pred(args):
    """å•ä¸ªy_predçš„MCTSè§„åˆ™å‘ç°ï¼ˆç”¨äºå¹¶è¡Œè®¡ç®—ï¼‰"""
    df, predicates, y_pred, max_depth, n_iter = args
    feature_predicates = [p for p in predicates if p not in [y_pred]]
    
    root = MCTSNode([y_pred])
    best_support, best_confidence = 0, 0.0
    best_rule = []
    
    for _ in range(n_iter):
        node = root
        # Selection
        while node.children:
            node = node.best_child()
        # Expansion
        if not node.is_terminal(max_depth, feature_predicates):
            node.expand(feature_predicates)
            if node.children:
                node = random.choice(node.children)
        # Simulation
        sim_preds = list(node.predicates)
        unused = list(set(feature_predicates) - set(sim_preds[1:]))
        while len(sim_preds) < max_depth and unused:
            sim_preds.append(random.choice(unused))
            unused = list(set(feature_predicates) - set(sim_preds[1:]))
        # è¯„ä¼°ï¼šå‰æ=sim_preds[1:], ç»“è®º=sim_preds[0]
        support, confidence = evaluate_rule(df, [sim_preds[0]] + sim_preds[1:])
        reward = support * confidence
        # Backpropagation
        tmp_node = node
        while tmp_node:
            tmp_node.visits += 1
            tmp_node.value += reward
            tmp_node = tmp_node.parent
        if reward > best_support * best_confidence:
            best_support, best_confidence = support, confidence
            best_rule = list(sim_preds)
    
    return (y_pred, best_rule, best_support, best_confidence)

def mcts_rule_discovery_yroot(df, predicates, enum_predicates, max_depth=3, n_iter=100, n_workers=None, use_parallel=True):
    """
    åˆ†å¸ƒå¼MCTSè§„åˆ™å‘ç°
    
    Args:
        df: æ•°æ®æ¡†
        predicates: æ‰€æœ‰è°“è¯
        enum_predicates: æšä¸¾å‹è°“è¯ï¼ˆä½œä¸ºç»“è®ºï¼‰
        max_depth: æœ€å¤§è§„åˆ™æ·±åº¦
        n_iter: æ¯ä¸ªy_predçš„è¿­ä»£æ¬¡æ•°
        n_workers: å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨CPUæ ¸å¿ƒæ•°
    """
    if not use_parallel or len(enum_predicates) < 5:
        # å•çº¿ç¨‹æ¨¡å¼ï¼ˆç”¨äºè°ƒè¯•æˆ–å°è§„æ¨¡æ•°æ®ï¼‰
        print(f"ğŸ”„ ä½¿ç”¨å•çº¿ç¨‹MCTS: {len(enum_predicates)}ä¸ªy_pred")
        start_time = time.time()
        results = []
        for i, y_pred in enumerate(enum_predicates):
            result = mcts_rule_discovery_single_y_pred((df, predicates, y_pred, max_depth, n_iter))
            results.append(result)
            if (i + 1) % max(1, len(enum_predicates) // 10) == 0:
                print(f"ğŸ“Š è¿›åº¦: {i+1}/{len(enum_predicates)} ({(i+1)/len(enum_predicates)*100:.1f}%)")
        return results
    
    # å¤šçº¿ç¨‹æ¨¡å¼
    if n_workers is None:
        n_workers = min(mp.cpu_count(), len(enum_predicates))
    
    print(f"ğŸš€ å¯åŠ¨åˆ†å¸ƒå¼MCTSè§„åˆ™å‘ç°: {len(enum_predicates)}ä¸ªy_pred, {n_workers}ä¸ªå·¥ä½œè¿›ç¨‹")
    start_time = time.time()
    
    # å‡†å¤‡å‚æ•°
    args_list = [(df, predicates, y_pred, max_depth, n_iter) for y_pred in enum_predicates]
    
    # ä½¿ç”¨è¿›ç¨‹æ± è¿›è¡Œå¹¶è¡Œè®¡ç®—
    results = []
    with ProcessPoolExecutor(max_workers=n_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_y_pred = {executor.submit(mcts_rule_discovery_single_y_pred, args): args[2] 
                           for args in args_list}
        
        # æ”¶é›†ç»“æœ
        completed = 0
        for future in as_completed(future_to_y_pred):
            y_pred = future_to_y_pred[future]
            try:
                result = future.result()
                results.append(result)
                completed += 1
                if completed % max(1, len(enum_predicates) // 10) == 0:
                    print(f"ğŸ“Š è¿›åº¦: {completed}/{len(enum_predicates)} ({completed/len(enum_predicates)*100:.1f}%)")
            except Exception as e:
                print(f"âŒ y_pred {y_pred} å¤„ç†å¤±è´¥: {e}")
                # æ·»åŠ é»˜è®¤ç»“æœ
                results.append((y_pred, [], 0, 0.0))
    
    elapsed_time = time.time() - start_time
    print(f"âœ… åˆ†å¸ƒå¼MCTSå®Œæˆ: {len(results)}ä¸ªè§„åˆ™, è€—æ—¶ {elapsed_time:.2f}ç§’")
    
    # æ‰“å°æ€§èƒ½ç»Ÿè®¡
    print_performance_stats(start_time, len(enum_predicates), n_workers)
    
    return results


def get_distributed_config():
    """è·å–åˆ†å¸ƒå¼è®¡ç®—é…ç½®"""
    config = {
        'n_workers': None,  # Noneè¡¨ç¤ºä½¿ç”¨CPUæ ¸å¿ƒæ•°
        'use_multiprocessing': True,  # æ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹
        'chunk_size': 10,  # æ¯ä¸ªè¿›ç¨‹å¤„ç†çš„y_predæ•°é‡
        'max_workers': mp.cpu_count(),  # æœ€å¤§å·¥ä½œè¿›ç¨‹æ•°
    }
    
    # å¯ä»¥æ ¹æ®æ•°æ®è§„æ¨¡è°ƒæ•´
    if config['max_workers'] > 8:
        config['n_workers'] = 8  # é™åˆ¶æœ€å¤§è¿›ç¨‹æ•°
    else:
        config['n_workers'] = config['max_workers']
    
    return config

def print_performance_stats(start_time, n_y_preds, n_workers):
    """æ‰“å°æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
    elapsed_time = time.time() - start_time
    avg_time_per_pred = elapsed_time / n_y_preds if n_y_preds > 0 else 0
    theoretical_speedup = n_workers if n_workers > 1 else 1
    
    print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
    print(f"   æ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
    print(f"   å¹³å‡æ¯ä¸ªy_predè€—æ—¶: {avg_time_per_pred:.2f}ç§’")
    print(f"   å·¥ä½œè¿›ç¨‹æ•°: {n_workers}")
    print(f"   ç†è®ºåŠ é€Ÿæ¯”: {theoretical_speedup}x")
    print(f"   å®é™…åŠ é€Ÿæ¯”: {elapsed_time / (avg_time_per_pred * n_y_preds / n_workers) if n_workers > 1 else 1:.2f}x")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Starting Multimodal DCRLearner Pipeline")
    
    # è·å–åˆ†å¸ƒå¼é…ç½®
    dist_config = get_distributed_config()
    print(f"ğŸ”§ åˆ†å¸ƒå¼é…ç½®: {dist_config}")
    
    # ä½¿ç”¨æ–°çš„æ•°æ®è·¯å¾„
    data_dir = "/data_nas/DCR/split_addnoise/goodreads_test"
    
    print(f"ğŸ“ Using data directory: {data_dir}")
    
    # æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_dir):
        print(f"âŒ Data directory not found: {data_dir}")
        return
    
    # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    required_files = ['train_clean.csv', 'test_clean.csv', 'test_dirty.csv']
    for file in required_files:
        file_path = os.path.join(data_dir, file)
        if not os.path.exists(file_path):
            print(f"âŒ Required file not found: {file_path}")
            return
        else:
            print(f"âœ… Found {file}")

    # ========== æ–°å¢ï¼šæ•°æ®ç±»å‹è¯†åˆ«ä¸embeddingé›†æˆ ==========
    # train_csv = os.path.join(data_dir, 'train_clean.csv')
    # test_csv = os.path.join(data_dir, 'test_clean.csv')
    # imgs_dir = os.path.join(data_dir, 'imgs')
    # if not os.path.exists(train_csv) or not os.path.exists(test_csv):
    #     print(f"âŒ train_clean.csv æˆ– test_clean.csv ä¸å­˜åœ¨")
    #     return
    # df_train = pd.read_csv(train_csv)
    # df_test = pd.read_csv(test_csv)
    # df_all = pd.concat([df_train, df_test], ignore_index=True)
    # print(f"ğŸ“Š åˆå¹¶åæ•°æ® shape: {df_all.shape}")

    # # åˆå§‹åŒ–æ¨¡å‹
    # model = MultimodalModels(device='cuda')

    # # è‡ªåŠ¨è¯†åˆ«åˆ—ç±»å‹
    # col_types = {}
    # for col in df_all.columns:
    #     if "img_path" in col:
    #         col_types[col] = "img_path"
    #     elif df_all[col].dtype in ['float64', 'int64']:
    #         col_types[col] = "numeric"
    #     elif df_all[col].dtype == 'object':
    #         unique_count = df_all[col].nunique()
    #         avg_len = df_all[col].astype(str).apply(len).mean()
    #         if unique_count < 20:
    #             col_types[col] = "enum"
    #         elif avg_len > 20:
    #             col_types[col] = "text"
    #         else:
    #             col_types[col] = "enum"
    # print(f"ğŸ” åˆ—ç±»å‹è¯†åˆ«: {col_types}")

    # # å›¾ç‰‡ embedding
    # if "img_path" in col_types.values():
    #     img_col = [col for col, typ in col_types.items() if typ == "img_path"][0]
    #     img_paths = df_all[img_col].apply(lambda x: os.path.join(imgs_dir, str(x)))
    #     img_embeds = []
    #     img_categories = []
    #     for path in img_paths:
    #         img_feat = model.extract_image_features(path)
    #         img_category = model.extract_image_category(path)
    #         if img_feat is not None:
    #             img_embeds.append(img_feat.cpu().numpy())
    #         else:
    #             img_embeds.append(None)
    #         img_categories.append(img_category)
    #     df_all["img_embedding"] = img_embeds
    #     df_all["img_category"] = img_categories
    #     print(f"âœ… å›¾ç‰‡embeddingå’Œç±»åˆ«å·²æ·»åŠ ")

    #     # å±‚æ¬¡èšç±»å‰PCAé™ç»´
    #     from sklearn.decomposition import PCA
    #     from scipy.cluster.hierarchy import linkage, fcluster
    #     import numpy as np
    #     valid_indices = [i for i, emb in enumerate(img_embeds) if emb is not None]
    #     valid_embeds = np.array([img_embeds[i].flatten() for i in valid_indices])
    #     if len(valid_embeds) > 1:
    #         pca = PCA(n_components=64)
    #         reduced_embeds = pca.fit_transform(valid_embeds)
    #         Z = linkage(reduced_embeds, method='ward')
    #         max_clusters = min(10, len(valid_embeds))
    #         clusters = fcluster(Z, max_clusters, criterion='maxclust')
    #         img_embed_cluster = [None] * len(img_embeds)
    #         for idx, c in zip(valid_indices, clusters):
    #             img_embed_cluster[idx] = int(c)
    #         df_all[f"img_embed_cluster"] = img_embed_cluster
    #         print(f"âœ… å·²å®Œæˆå›¾ç‰‡embeddingçš„PCAé™ç»´+å±‚æ¬¡èšç±»ï¼Œèšç±»æ•°: {max(clusters)}")
    #     else:
    #         df_all["img_embed_cluster"] = [None] * len(img_embeds)
    #         print(f"âš ï¸ æœ‰æ•ˆå›¾ç‰‡embeddingæ•°é‡ä¸è¶³ï¼Œæœªèšç±»")

    # # æ–‡æœ¬ embedding
    # for col, typ in col_types.items():
    #     if typ == "text":
    #         text_embeds = []
    #         for text in df_all[col].astype(str):
    #             text_feat = model.extract_text_features(text)
    #             text_embeds.append(text_feat.cpu().numpy())
    #         df_all[f"text_embedding_{col}"] = text_embeds
    #         print(f"âœ… æ–‡æœ¬embeddingå·²æ·»åŠ : {col}")

    #         # æ–‡æœ¬embeddingå±‚æ¬¡èšç±»å‰PCAé™ç»´
    #         from sklearn.decomposition import PCA
    #         from scipy.cluster.hierarchy import linkage, fcluster
    #         import numpy as np
    #         valid_indices = [i for i, emb in enumerate(text_embeds) if emb is not None]
    #         valid_embeds = np.array([text_embeds[i].flatten() for i in valid_indices])
    #         if len(valid_embeds) > 1:
    #             pca = PCA(n_components=64)
    #             reduced_embeds = pca.fit_transform(valid_embeds)
    #             Z = linkage(reduced_embeds, method='ward')
    #             max_clusters = min(10, len(valid_embeds))
    #             clusters = fcluster(Z, max_clusters, criterion='maxclust')
    #             text_embed_cluster = [None] * len(text_embeds)
    #             for idx, c in zip(valid_indices, clusters):
    #                 text_embed_cluster[idx] = int(c)
    #             df_all[f"text_{col}_embed_cluster"] = text_embed_cluster
    #             print(f"âœ… å·²å®Œæˆæ–‡æœ¬embeddingçš„PCAé™ç»´+å±‚æ¬¡èšç±»: {col}ï¼Œèšç±»æ•°: {max(clusters)}")
    #         else:
    #             df_all[f"text_{col}_embed_cluster"] = [None] * len(text_embeds)
    #             print(f"âš ï¸ æœ‰æ•ˆæ–‡æœ¬embeddingæ•°é‡ä¸è¶³ï¼Œæœªèšç±»: {col}")

    # # ä¿å­˜ä¸ºpkl
    # out_pkl = os.path.join(data_dir, "train_with_embeddings.pkl")
    # df_all.to_pickle(out_pkl)
    # print(f"âœ… å·²ä¿å­˜å¸¦embeddingçš„æ•°æ®: {out_pkl}")

    # # ä¿å­˜ä¸ºcsvï¼Œåˆ†åˆ«æ‹†åˆ†train/test
    # n_train = len(df_train)
    # df_train_extend = df_all.iloc[:n_train].copy()
    # df_test_extend = df_all.iloc[n_train:].copy()
    # # åªä¿å­˜å¯åºåˆ—åŒ–çš„åˆ—ï¼ˆå»é™¤é«˜ç»´embeddingåˆ—ï¼‰
    # drop_cols = [col for col in df_all.columns if isinstance(df_all[col].iloc[0], (np.ndarray, list, dict, torch.Tensor))]
    # df_train_csv = df_train_extend.drop(columns=drop_cols)
    # df_test_csv = df_test_extend.drop(columns=drop_cols)
    # df_train_csv.to_csv(os.path.join(data_dir, "train_extend.csv"), index=False)
    # df_test_csv.to_csv(os.path.join(data_dir, "test_extend.csv"), index=False)
    # print(f"âœ… å·²ä¿å­˜æ‰©å±•ç‰¹å¾çš„csv: train_extend.csv, test_extend.csv")

    
    df_train_csv=pd.read_csv(os.path.join(data_dir, "train_extend.csv"))
    df_test_csv=pd.read_csv(os.path.join(data_dir, "test_extend.csv"))
    test_dirty=pd.read_csv(os.path.join(data_dir, "test_dirty.csv"))
    
    # test_dirtyèšç±»æ ‡ç­¾ç›´æ¥ç”¨test_cleançš„ï¼ˆå‡è®¾ä¸€ä¸€å¯¹åº”ï¼‰
    for col in df_test_csv.columns:
        if ("embed_cluster" in col or "img_category" in col) and col not in test_dirty.columns:
            # ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´ï¼Œé¿å…æµ®ç‚¹æ•°vsæ•´æ•°çš„æ¯”è¾ƒé—®é¢˜
            test_dirty[col] = df_test_csv[col].astype(str).values
    test_dirty.to_csv(os.path.join(data_dir, "test_dirty_extend.csv"), index=False)
    print(f"âœ… å·²ä¿å­˜æ‰©å±•ç‰¹å¾çš„csv: test_dirty_extend.csv")


    # åç»­pipelineç”¨train_extend.csvã€test_dirty_extend.csv
    out_csv = os.path.join(data_dir, "train_extend.csv")

    # æ„é€ è°“è¯å¹¶ä¿å­˜
    pc = PredicateConstructor(out_csv)
    predicates = pc.construct_predicates()
    with open(os.path.join(data_dir, "predicates.txt"), "w", encoding="utf-8") as f:
        for p in predicates:
            f.write(p + "\n")
    print(f"âœ… å·²ä¿å­˜æ‰€æœ‰æ„é€ è°“è¯åˆ°: {os.path.join(data_dir, 'predicates.txt')}")

    # MCTSè§„åˆ™å‘ç°ï¼ˆä»¥æšä¸¾å‹è°“è¯ä¸ºY predicateï¼‰
    mcts_df = pd.read_csv(out_csv)
    with open(os.path.join(data_dir, 'predicates.txt'), 'r', encoding='utf-8') as f:
        mcts_predicates = [line.strip() for line in f if line.strip()]
    # æ”¯æŒåº¦ç­›é€‰ï¼Œå‡å°‘MCTSæœç´¢ç©ºé—´
    support_filter_threshold = 0.05  # é™ä½é˜ˆå€¼ï¼Œåªä¿ç•™æ”¯æŒåº¦å¤§äº0.5%çš„è°“è¯
    max_predicates = 1000  # é™åˆ¶æœ€å¤§è°“è¯æ•°é‡
    filtered_predicates = []
    for p in mcts_predicates:
        mask = predicate_mask(mcts_df, p)
        support = mask.sum() / len(mcts_df) if len(mcts_df) > 0 else 0
        if support >= support_filter_threshold:
            filtered_predicates.append(p)
        if len(filtered_predicates) >= max_predicates:  # è¾¾åˆ°ä¸Šé™å°±åœæ­¢
            break
    print(f'âœ… æ”¯æŒåº¦ç­›é€‰åè°“è¯æ•°: {len(filtered_predicates)} (åŸå§‹: {len(mcts_predicates)})')
    # æšä¸¾å‹è°“è¯ç­›é€‰ï¼ˆå¦‚ t0.col = ... where colä¸ºæšä¸¾å‹ï¼‰
    enum_predicates = [p for p in filtered_predicates if re.search(r'=\s*"', p)]
    print(f'âœ… æšä¸¾å‹è°“è¯æ•°: {len(enum_predicates)}')
    
    # ä¸ºGoodreadsæ•°æ®é›†æ„å»ºä¸“é—¨çš„è°“è¯
    
    # ä¸ºgenreåˆ—æ·»åŠ ä¸“é—¨çš„è°“è¯ï¼ˆå›¾ä¹¦ç±»å‹ï¼‰
    if 'genre' in mcts_df.columns:
        genre_vals = mcts_df['genre'].dropna().unique()
        # åªå–å‰15ä¸ªæœ€å¸¸è§çš„ç±»å‹ï¼Œé¿å…è°“è¯çˆ†ç‚¸
        genre_vals = genre_vals[:15] if len(genre_vals) > 15 else genre_vals
        for val in genre_vals:
            if pd.notna(val) and str(val).strip() != '':
                enum_predicates.append(f'genre = "{val}"')
        print(f'âœ… ä¸ºgenreåˆ—æ·»åŠ äº† {len(genre_vals)} ä¸ªè°“è¯')
        
        # æ·»åŠ genreçš„é”™è¯¯æ¨¡å¼è°“è¯ï¼ˆåªæ·»åŠ æœ€é‡è¦çš„å‡ ä¸ªï¼‰
        important_genres = [
            'genre = "Fiction"',      # æ£€æµ‹å°è¯´ç›¸å…³çš„é”™è¯¯
            'genre = "Non-Fiction"',  # æ£€æµ‹éå°è¯´ç›¸å…³çš„é”™è¯¯
            'genre = "Mystery"',      # æ£€æµ‹æ‚¬ç–‘ç›¸å…³çš„é”™è¯¯
            'genre = "Romance"',      # æ£€æµ‹è¨€æƒ…ç›¸å…³çš„é”™è¯¯
            'genre = "Science Fiction"',  # æ£€æµ‹ç§‘å¹»ç›¸å…³çš„é”™è¯¯
        ]
        for pred in important_genres:
            if pred not in enum_predicates:
                enum_predicates.append(pred)
        print(f'âœ… æ·»åŠ äº†genreé‡è¦é”™è¯¯æ¨¡å¼è°“è¯')
    
    # ä¸ºlanguageåˆ—æ·»åŠ ä¸“é—¨çš„è°“è¯ï¼ˆè¯­è¨€ï¼‰
    if 'language' in mcts_df.columns:
        language_vals = mcts_df['language'].dropna().unique()
        for val in language_vals:
            if pd.notna(val) and str(val).strip() != '':
                enum_predicates.append(f'language = "{val}"')
        print(f'âœ… ä¸ºlanguageåˆ—æ·»åŠ äº† {len(language_vals)} ä¸ªè°“è¯')
        
        # æ·»åŠ languageçš„é”™è¯¯æ¨¡å¼è°“è¯
        important_languages = [
            'language = "English"',   # æ£€æµ‹è‹±è¯­ç›¸å…³çš„é”™è¯¯
            'language = "Spanish"',   # æ£€æµ‹è¥¿ç­ç‰™è¯­ç›¸å…³çš„é”™è¯¯
            'language = "French"',    # æ£€æµ‹æ³•è¯­ç›¸å…³çš„é”™è¯¯
            'language = "German"',    # æ£€æµ‹å¾·è¯­ç›¸å…³çš„é”™è¯¯
        ]
        for pred in important_languages:
            if pred not in enum_predicates:
                enum_predicates.append(pred)
        print(f'âœ… æ·»åŠ äº†languageé‡è¦é”™è¯¯æ¨¡å¼è°“è¯')
    
    # ä¸ºformatåˆ—æ·»åŠ ä¸“é—¨çš„è°“è¯ï¼ˆå›¾ä¹¦æ ¼å¼ï¼‰
    if 'format' in mcts_df.columns:
        format_vals = mcts_df['format'].dropna().unique()
        for val in format_vals:
            if pd.notna(val) and str(val).strip() != '':
                enum_predicates.append(f'format = "{val}"')
        print(f'âœ… ä¸ºformatåˆ—æ·»åŠ äº† {len(format_vals)} ä¸ªè°“è¯')
        
        # æ·»åŠ formatçš„é”™è¯¯æ¨¡å¼è°“è¯
        important_formats = [
            'format = "Paperback"',   # æ£€æµ‹å¹³è£…æœ¬ç›¸å…³çš„é”™è¯¯
            'format = "Hardcover"',   # æ£€æµ‹ç²¾è£…æœ¬ç›¸å…³çš„é”™è¯¯
            'format = "Ebook"',       # æ£€æµ‹ç”µå­ä¹¦ç›¸å…³çš„é”™è¯¯
            'format = "Audiobook"',   # æ£€æµ‹æœ‰å£°ä¹¦ç›¸å…³çš„é”™è¯¯
        ]
        for pred in important_formats:
            if pred not in enum_predicates:
                enum_predicates.append(pred)
        print(f'âœ… æ·»åŠ äº†formaté‡è¦é”™è¯¯æ¨¡å¼è°“è¯')
    
    # ä¸ºpublisheråˆ—æ·»åŠ ä¸“é—¨çš„è°“è¯ï¼ˆå‡ºç‰ˆç¤¾ï¼‰
    if 'publisher' in mcts_df.columns:
        publisher_vals = mcts_df['publisher'].dropna().unique()
        # åªå–å‰10ä¸ªæœ€å¸¸è§çš„å‡ºç‰ˆç¤¾ï¼Œé¿å…è°“è¯çˆ†ç‚¸
        publisher_vals = publisher_vals[:10] if len(publisher_vals) > 10 else publisher_vals
        for val in publisher_vals:
            if pd.notna(val) and str(val).strip() != '':
                enum_predicates.append(f'publisher = "{val}"')
        print(f'âœ… ä¸ºpublisheråˆ—æ·»åŠ äº† {len(publisher_vals)} ä¸ªè°“è¯')
        
        # æ·»åŠ publisherçš„é”™è¯¯æ¨¡å¼è°“è¯
        important_publishers = [
            'publisher = "Penguin"',      # æ£€æµ‹ä¼é¹…å‡ºç‰ˆç¤¾ç›¸å…³çš„é”™è¯¯
            'publisher = "Random House"', # æ£€æµ‹å…°ç™»ä¹¦å±‹ç›¸å…³çš„é”™è¯¯
            'publisher = "HarperCollins"', # æ£€æµ‹å“ˆç€æŸ¯æ—æ–¯ç›¸å…³çš„é”™è¯¯
        ]
        for pred in important_publishers:
            if pred not in enum_predicates:
                enum_predicates.append(pred)
        print(f'âœ… æ·»åŠ äº†publisheré‡è¦é”™è¯¯æ¨¡å¼è°“è¯')
    
    # ä¸ºratingåˆ—æ·»åŠ ä¸“é—¨çš„è°“è¯ï¼ˆè¯„åˆ†ï¼‰
    if 'rating' in mcts_df.columns:
        rating_vals = mcts_df['rating'].dropna().unique()
        for val in rating_vals:
            if pd.notna(val):
                enum_predicates.append(f'rating = "{val}"')
        print(f'âœ… ä¸ºratingåˆ—æ·»åŠ äº† {len(rating_vals)} ä¸ªè°“è¯')
        
        # æ·»åŠ ratingçš„é”™è¯¯æ¨¡å¼è°“è¯
        important_ratings = [
            'rating = "5"',  # æ£€æµ‹5æ˜Ÿè¯„åˆ†ç›¸å…³çš„é”™è¯¯
            'rating = "4"',  # æ£€æµ‹4æ˜Ÿè¯„åˆ†ç›¸å…³çš„é”™è¯¯
            'rating = "3"',  # æ£€æµ‹3æ˜Ÿè¯„åˆ†ç›¸å…³çš„é”™è¯¯
        ]
        for pred in important_ratings:
            if pred not in enum_predicates:
                enum_predicates.append(pred)
        print(f'âœ… æ·»åŠ äº†ratingé‡è¦é”™è¯¯æ¨¡å¼è°“è¯')
    
    # ä¸ºavailabilityåˆ—æ·»åŠ ä¸“é—¨çš„è°“è¯ï¼ˆå¯ç”¨æ€§ï¼‰
    if 'availability' in mcts_df.columns:
        availability_vals = mcts_df['availability'].dropna().unique()
        for val in availability_vals:
            if pd.notna(val):
                enum_predicates.append(f'availability = "{val}"')
        print(f'âœ… ä¸ºavailabilityåˆ—æ·»åŠ äº† {len(availability_vals)} ä¸ªè°“è¯')
        
        # æ·»åŠ availabilityçš„é”™è¯¯æ¨¡å¼è°“è¯
        availability_errors = [
            'availability = "Available"',   # æ£€æµ‹å¯ç”¨ç›¸å…³çš„é”™è¯¯
            'availability = "Out of Stock"', # æ£€æµ‹ç¼ºè´§ç›¸å…³çš„é”™è¯¯
        ]
        for pred in availability_errors:
            if pred not in enum_predicates:
                enum_predicates.append(pred)
        print(f'âœ… æ·»åŠ äº†availabilityé”™è¯¯æ¨¡å¼è°“è¯')
    
    print(f'âœ… æœ€ç»ˆæšä¸¾å‹è°“è¯æ•°: {len(enum_predicates)}')
    # é™åˆ¶æšä¸¾å‹è°“è¯æ•°é‡ï¼Œé¿å…MCTSæœç´¢è¿‡æ…¢
    # if len(enum_predicates) > 50:
    #     enum_predicates = enum_predicates[:50]
    #     print(f'âœ… é™åˆ¶æšä¸¾å‹è°“è¯æ•°ä¸º: {len(enum_predicates)}')
    # ä½¿ç”¨åˆ†å¸ƒå¼MCTSè§„åˆ™å‘ç°
    print(f"ğŸ¯ å¼€å§‹åˆ†å¸ƒå¼MCTSè§„åˆ™å‘ç°...")
    print(f"   æ•°æ®è§„æ¨¡: {len(mcts_df)}è¡Œ, {len(filtered_predicates)}ä¸ªè°“è¯, {len(enum_predicates)}ä¸ªy_pred")
    
    # ç­–ç•¥1: å…¨å±€è§„åˆ™å‘ç°
    print(f"ğŸ” ç­–ç•¥1: å…¨å±€è§„åˆ™å‘ç°...")
    mcts_results = mcts_rule_discovery_yroot(
        mcts_df, 
        filtered_predicates, 
        enum_predicates, 
        max_depth=6,  # è¿›ä¸€æ­¥å¢åŠ æœç´¢æ·±åº¦ä»¥å‘ç°æ›´å¤æ‚çš„è§„åˆ™
        n_iter=10000,  # å¤§å¹…å¢åŠ è¿­ä»£æ¬¡æ•°ä»¥æé«˜å¬å›ç‡
        n_workers=dist_config['n_workers'],
        use_parallel=dist_config['use_multiprocessing']
    )
    
    # ç­–ç•¥2: é’ˆå¯¹ç‰¹å®šåˆ—çš„ä¸“é—¨è§„åˆ™å‘ç°
    print(f"ğŸ” ç­–ç•¥2: é’ˆå¯¹ç‰¹å®šåˆ—çš„ä¸“é—¨è§„åˆ™å‘ç°...")
    target_columns = ['genre', 'language', 'format', 'publisher', 'rating', 'availability']
    specialized_results = []
    
    for target_col in target_columns:
        if target_col in mcts_df.columns:
            print(f"  ğŸ¯ ä¸º{target_col}åˆ—å‘ç°ä¸“é—¨è§„åˆ™...")
            # ä¸ºè¯¥åˆ—åˆ›å»ºä¸“é—¨çš„y_pred
            col_vals = mcts_df[target_col].dropna().unique()
            col_predicates = [f'{target_col} = "{val}"' for val in col_vals if pd.notna(val) and str(val).strip() != '']
            
            if col_predicates:
                # é™åˆ¶è°“è¯æ•°é‡ä»¥é¿å…æœç´¢è¿‡æ…¢
                col_predicates = col_predicates[:15]  # å¢åŠ è°“è¯æ•°é‡ä»¥æ•è·æ›´å¤šæ¨¡å¼
                print(f"    {target_col}åˆ—è°“è¯æ•°: {len(col_predicates)}")
                
                # ä¸ºè¯¥åˆ—è¿›è¡Œä¸“é—¨çš„MCTSæœç´¢
                col_results = mcts_rule_discovery_yroot(
                    mcts_df,
                    filtered_predicates,
                    col_predicates,
                    max_depth=6,  # è¿›ä¸€æ­¥å¢åŠ æ·±åº¦ä»¥å‘ç°æ›´å¤æ‚çš„è§„åˆ™
                    n_iter=5000,  # å¢åŠ è¿­ä»£æ¬¡æ•°ä»¥æé«˜å‘ç°æ¦‚ç‡
                    n_workers=dist_config['n_workers'],
                    use_parallel=dist_config['use_multiprocessing']
                )
                specialized_results.extend(col_results)
                print(f"    âœ… {target_col}åˆ—å‘ç° {len(col_results)} ä¸ªè§„åˆ™")
    
    # åˆå¹¶æ‰€æœ‰ç»“æœ
    all_results = mcts_results + specialized_results
    print(f"âœ… æ€»è§„åˆ™æ•°: {len(all_results)} (å…¨å±€: {len(mcts_results)}, ä¸“é—¨: {len(specialized_results)})")
    # é˜ˆå€¼è®¾ç½® - é€‚åº¦ä¼˜åŒ–ä»¥æé«˜å¬å›ç‡
    support_threshold = 0.2  # é€‚åº¦é™ä½æ”¯æŒåº¦é˜ˆå€¼ä»¥å‘ç°æ›´å¤šè§„åˆ™
    confidence_threshold = 0.65  # é€‚åº¦é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ä»¥æé«˜å¬å›ç‡
    # ä¿å­˜ä¸ºç»“æ„åŒ–csv
    rules_data = []
    for y_pred, rule, support, confidence in all_results:
        if support >= support_threshold and confidence >= confidence_threshold:
            # é¢å¤–çš„è´¨é‡è¿‡æ»¤ï¼šé¿å…è¿‡äºå®½æ³›çš„è§„åˆ™
            rule_complexity = len(rule) - 1  # å‰ææ¡ä»¶çš„æ•°é‡
            if rule_complexity >= 1:  # è‡³å°‘éœ€è¦1ä¸ªå‰ææ¡ä»¶ï¼ˆæ”¾å®½è¦æ±‚ï¼‰
                rules_data.append({
                    'y_pred': y_pred,
                    'best_rule': ' ^ '.join(rule[1:]),
                    'support': support,
                    'confidence': confidence
                })
    
    print(f'ğŸ” è´¨é‡è¿‡æ»¤åä¿ç•™ {len(rules_data)} ä¸ªè§„åˆ™ (æ€»å‘ç° {len(all_results)} ä¸ª)')
    rules_df = pd.DataFrame(rules_data)
    if not rules_df.empty:
        rules_df.to_csv(os.path.join(data_dir, 'dcr_mcts_rule.csv'), index=False)
        print(f'âœ… å‘ç° {len(rules_df)} ä¸ªæœ‰æ•ˆè§„åˆ™')
        print(f'ğŸ“Š è§„åˆ™åˆ†å¸ƒ:')
        for col in ['genre', 'language', 'format', 'publisher', 'rating', 'availability']:
            col_rules = rules_df[rules_df['y_pred'].str.contains(col, na=False)]
            print(f'  {col}: {len(col_rules)} ä¸ªè§„åˆ™')
    else:
        rules_df = pd.DataFrame(columns=['y_pred', 'best_rule', 'support', 'confidence'])
        rules_df.to_csv(os.path.join(data_dir, 'dcr_mcts_rule.csv'), index=False)
        print('âš ï¸ æœªå‘ç°ä»»ä½•æœ‰æ•ˆè§„åˆ™')
    print(f'âœ… å·²ä¿å­˜ç»“æ„åŒ–è§„åˆ™è¡¨åˆ°: {os.path.join(data_dir, "dcr_mcts_rule.csv")}')

    # è§„åˆ™æŸ¥é”™ï¼šè¾“å‡ºerror_cell (è¡Œå·, åˆ—å)
    rules_df = pd.read_csv(os.path.join(data_dir, 'dcr_mcts_rule.csv'))
    test_dirty = pd.read_csv(os.path.join(data_dir, 'test_dirty_extend.csv'))
    test_clean = pd.read_csv(os.path.join(data_dir, 'test_extend.csv'))

    results = []
    def extract_col_from_predicate(pred):
        import re
        m = re.match(r'(\w+)\s*[=!<>]+\s*.+', pred)
        if m:
            return m.group(1)
        return None
    # æ’é™¤ä¸åº”è¯¥æœ‰é”™è¯¯çš„åˆ—
    exclude_cols = [col for col in test_dirty.columns if "embed_cluster" in col or "img_category" in col]
    
    for idx, row in rules_df.iterrows():
        y_pred = row['y_pred']
        best_rule = row['best_rule']
        # è§£æå‰æè°“è¯
        premise_preds = [p.strip() for p in best_rule.split('^') if p.strip()]
        # ç»“è®ºè°“è¯
        conclusion_pred = y_pred
        conclusion_col = extract_col_from_predicate(conclusion_pred)
        if conclusion_col is None or conclusion_col in exclude_cols:
            continue  # è·³è¿‡æ— æ³•æå–åˆ—åçš„è§„åˆ™æˆ–ä¸åº”è¯¥æœ‰é”™è¯¯çš„åˆ—
        # å‰æmask
        mask = np.ones(len(test_dirty), dtype=bool)
        for pred in premise_preds:
            mask = mask & predicate_mask(test_dirty, pred)
        # ç»“è®ºmask
        mask_conclusion = predicate_mask(test_dirty, conclusion_pred)
        # æŸ¥é”™ï¼šå‰ææˆç«‹ä½†ç»“è®ºä¸æˆç«‹çš„æ ·æœ¬
        error_mask = mask & (~mask_conclusion)
        
        # è¿‡æ»¤æ‰NaNå€¼å’Œè¯¯æŠ¥
        for i in range(len(test_dirty)):
            if error_mask[i]:
                clean_val = test_clean.iloc[i][conclusion_col] if i < len(test_clean) else None
                dirty_val = test_dirty.iloc[i][conclusion_col]
                # å¦‚æœä¸¤ä¸ªå€¼éƒ½æ˜¯NaNï¼Œä¸ç®—é”™è¯¯
                if pd.isna(clean_val) and pd.isna(dirty_val):
                    error_mask[i] = False
                # å¦‚æœä¸¤ä¸ªå€¼ç›¸åŒï¼Œä¸ç®—é”™è¯¯ï¼ˆé¿å…è¯¯æŠ¥ï¼‰
                elif not pd.isna(clean_val) and not pd.isna(dirty_val):
                    if str(clean_val).strip() == str(dirty_val).strip():
                        error_mask[i] = False
        
        # ä½¿ç”¨ä½ç½®ç´¢å¼•è€Œä¸æ˜¯DataFrameç´¢å¼•ï¼Œç¡®ä¿ä¸€è‡´æ€§
        error_positions = [i for i, is_error in enumerate(error_mask) if is_error]
        # è¾“å‡ºerror_cell
        error_cells = [(i, conclusion_col) for i in error_positions]
        if error_cells:
            results.append({
                'rule_id': idx,
                'y_pred': y_pred,
                'best_rule': best_rule,
                'error_cell': json.dumps(error_cells),
                'error_count': len(error_cells)
            })
    error_df = pd.DataFrame(results)
    if not error_df.empty:
        error_df.to_csv(os.path.join(data_dir, 'dcr_rule_error_detect.csv'), index=False)
    else:
        # æ˜ç¡®æŒ‡å®šåˆ—åï¼Œå†™å…¥è¡¨å¤´
        error_df = pd.DataFrame(columns=['rule_id', 'y_pred', 'best_rule', 'error_cell', 'error_count'])
        error_df.to_csv(os.path.join(data_dir, 'dcr_rule_error_detect.csv'), index=False)
    print('âœ… å·²ä¿å­˜è§„åˆ™æŸ¥é”™ç»“æœåˆ° dcr_rule_error_detect.csv')

    # è§„åˆ™æŸ¥é”™è¯„ä¼°ï¼šä¸test_clean.csvå¯¹æ¯”ï¼Œè®¡ç®—F1/recall/precision/accuracy
    import ast
    error_file = os.path.join(data_dir, 'dcr_rule_error_detect.csv')
    # åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºç©ºæˆ–æ— åˆ—
    if os.path.getsize(error_file) == 0 or pd.read_csv(error_file).shape[1] == 0:
        print("âš ï¸ æŸ¥é”™ç»“æœæ–‡ä»¶ä¸ºç©ºæˆ–æ— åˆ—ï¼Œè·³è¿‡è¯„ä¼°ã€‚")
        with open(os.path.join(data_dir, 'dcr_rule_error_metrics.txt'), 'w', encoding='utf-8') as f:
            f.write('Precision: 0.0000\nRecall: 0.0000\nF1: 0.0000\nAccuracy: 0.0000\n')
        return

    test_clean = pd.read_csv(os.path.join(data_dir, 'test_extend.csv'))    
    test_dirty = pd.read_csv(os.path.join(data_dir, 'test_dirty_extend.csv'))
    
    # æ‰“å°æ•°æ®æ¡†å¤§å°ä¿¡æ¯
    print(f"ğŸ“Š æ•°æ®æ¡†å¤§å°ä¿¡æ¯:")
    print(f"   test_clean.shape: {test_clean.shape}")
    print(f"   test_dirty.shape: {test_dirty.shape}")
    print(f"   test_clean.columns: {list(test_clean.columns)}")
    print(f"   test_dirty.columns: {list(test_dirty.columns)}") 
    
    # é¢„æµ‹ä¸ºæ­£çš„cellé›†åˆ
    pred_cells = set()
    for cells in error_df['error_cell']:
        for cell in json.loads(cells):
            row_idx, col_name = cell
            # éªŒè¯ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
            if row_idx >= len(test_clean):
                print(f"âš ï¸ è­¦å‘Šï¼šé¢„æµ‹é”™è¯¯ç´¢å¼•è¶…å‡ºèŒƒå›´: è¡Œ{row_idx}, åˆ—{col_name} (test_clean.shape={test_clean.shape})")
                continue
            if col_name not in test_clean.columns:
                print(f"âš ï¸ è­¦å‘Šï¼šé¢„æµ‹é”™è¯¯åˆ—ä¸å­˜åœ¨: è¡Œ{row_idx}, åˆ—{col_name}")
                continue
            pred_cells.add(tuple(cell))
    
    print(f"ğŸ“Š æœ‰æ•ˆé¢„æµ‹é”™è¯¯æ•°: {len(pred_cells)}")
    
    # å®é™…ä¸ºæ­£çš„cellé›†åˆ
    real_cells = set()
    # æ’é™¤ä¸åº”è¯¥æœ‰é”™è¯¯çš„åˆ—ï¼ˆembeddingèšç±»åˆ—å’Œå›¾ç‰‡ç±»åˆ«åˆ—ï¼‰
    exclude_cols = [col for col in test_clean.columns if "embed_cluster" in col or "img_category" in col]
    print(f"ğŸ” æ’é™¤çš„åˆ—ï¼ˆä¸åº”è¯¥æœ‰é”™è¯¯ï¼‰: {exclude_cols}")
    
    for i in range(len(test_clean)):
        for col in test_clean.columns:
            # è·³è¿‡ä¸åº”è¯¥æœ‰é”™è¯¯çš„åˆ—
            if col in exclude_cols:
                continue
            clean_val = test_clean.at[i, col]
            dirty_val = test_dirty.at[i, col]
            # æ­£ç¡®å¤„ç†NaNå€¼æ¯”è¾ƒ
            if pd.isna(clean_val) and pd.isna(dirty_val):
                continue  # ä¸¤ä¸ªéƒ½æ˜¯NaNï¼Œä¸ç®—é”™è¯¯
            elif pd.isna(clean_val) or pd.isna(dirty_val):
                real_cells.add((i, col))  # ä¸€ä¸ªNaNä¸€ä¸ªéNaNï¼Œç®—é”™è¯¯
            elif str(clean_val).strip() != str(dirty_val).strip():
                real_cells.add((i, col))  # å­—ç¬¦ä¸²æ¯”è¾ƒï¼Œå»é™¤ç©ºæ ¼
    
    # è®¡ç®—æŒ‡æ ‡
    TP = len(pred_cells & real_cells)
    FP = len(pred_cells - real_cells)
    FN = len(real_cells - pred_cells)
    total_cells = test_clean.shape[0] * test_clean.shape[1]
    TN = total_cells - TP - FP - FN
    precision = TP / (TP + FP) if (TP + FP) > 0 else 0
    recall = TP / (TP + FN) if (TP + FN) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    accuracy = (TP + TN) / total_cells
    
    print(f'Precision: {precision:.4f}')
    print(f'Recall: {recall:.4f}')
    print(f'F1: {f1:.4f}')
    print(f'Accuracy: {accuracy:.4f}')
    
    # ========== é”™è¯¯ç»Ÿè®¡åˆ†æ ==========
    print(f"\nğŸ“Š é”™è¯¯ç»Ÿè®¡åˆ†æ:")
    print(f"æ€»å•å…ƒæ ¼æ•°: {total_cells}")
    print(f"å®é™…é”™è¯¯æ•°: {len(real_cells)}")
    print(f"é¢„æµ‹é”™è¯¯æ•°: {len(pred_cells)}")
    print(f"çœŸé˜³æ€§(TP): {TP}")
    print(f"å‡é˜³æ€§(FP): {FP}")
    print(f"å‡é˜´æ€§(FN): {FN}")
    print(f"çœŸé˜´æ€§(TN): {TN}")
    
    # åˆ†ææŸ¥åˆ°çš„é”™è¯¯ï¼ˆTPï¼‰
    if TP > 0:
        print(f"\nâœ… æŸ¥åˆ°çš„é”™è¯¯ (TP={TP}):")
        tp_cells = list(pred_cells & real_cells)
        tp_cells.sort()
        for i, (row_idx, col_name) in enumerate(tp_cells[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
            if row_idx < len(test_clean) and col_name in test_clean.columns:
                clean_val = test_clean.at[row_idx, col_name]
                dirty_val = test_dirty.at[row_idx, col_name]
                # æ­£ç¡®å¤„ç†NaNå€¼æ˜¾ç¤º
                clean_str = str(clean_val) if not pd.isna(clean_val) else 'NaN'
                dirty_str = str(dirty_val) if not pd.isna(dirty_val) else 'NaN'
                print(f"  {i+1}. è¡Œ{row_idx}, åˆ—{col_name}: '{clean_str}' -> '{dirty_str}'")
            else:
                print(f"  {i+1}. è¡Œ{row_idx}, åˆ—{col_name}: ç´¢å¼•è¶…å‡ºèŒƒå›´ (test_clean.shape={test_clean.shape})")
        if len(tp_cells) > 10:
            print(f"  ... è¿˜æœ‰ {len(tp_cells)-10} ä¸ªæŸ¥åˆ°çš„é”™è¯¯")
    
    # åˆ†ææœªæŸ¥åˆ°çš„é”™è¯¯ï¼ˆFNï¼‰
    if FN > 0:
        print(f"\nâŒ æœªæŸ¥åˆ°çš„é”™è¯¯ (FN={FN}):")
        fn_cells = list(real_cells - pred_cells)
        fn_cells.sort()
        for i, (row_idx, col_name) in enumerate(fn_cells[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
            if row_idx < len(test_clean) and col_name in test_clean.columns:
                clean_val = test_clean.at[row_idx, col_name]
                dirty_val = test_dirty.at[row_idx, col_name]
                # æ­£ç¡®å¤„ç†NaNå€¼æ˜¾ç¤º
                clean_str = str(clean_val) if not pd.isna(clean_val) else 'NaN'
                dirty_str = str(dirty_val) if not pd.isna(dirty_val) else 'NaN'
                print(f"  {i+1}. è¡Œ{row_idx}, åˆ—{col_name}: '{clean_str}' -> '{dirty_str}'")
            else:
                print(f"  {i+1}. è¡Œ{row_idx}, åˆ—{col_name}: ç´¢å¼•è¶…å‡ºèŒƒå›´ (test_clean.shape={test_clean.shape})")
        if len(fn_cells) > 10:
            print(f"  ... è¿˜æœ‰ {len(fn_cells)-10} ä¸ªæœªæŸ¥åˆ°çš„é”™è¯¯")
    
    # åˆ†æè¯¯æŠ¥çš„é”™è¯¯ï¼ˆFPï¼‰
    if FP > 0:
        print(f"\nâš ï¸ è¯¯æŠ¥çš„é”™è¯¯ (FP={FP}):")
        fp_cells = list(pred_cells - real_cells)
        fp_cells.sort()
        
        # å…ˆæ˜¾ç¤ºæ‰€æœ‰è§„åˆ™ï¼Œå¸®åŠ©ç†è§£è¯¯æŠ¥åŸå› 
        print(f"ğŸ” å½“å‰æ‰€æœ‰è§„åˆ™:")
        print(f"error_df columns: {error_df.columns.tolist()}")
        print(f"rules_df columns: {rules_df.columns.tolist()}")
        for idx, row in error_df.iterrows():
            rule_id = row['rule_id']
            rule_info = f"  Rule_{rule_id}: {row['y_pred']} <- {row['best_rule']}"
            # ä»rules_dfæŸ¥support/confidence
            if rule_id < len(rules_df):
                rule_row = rules_df.iloc[rule_id]
                rule_info += f" (support={rule_row['support']:.3f}, confidence={rule_row['confidence']:.3f})"
            print(rule_info)

        # åˆ†æè¯¯æŠ¥çš„è§„åˆ™æ¥æº
        print(f"\nğŸ” è¯¯æŠ¥åˆ†æ - æ£€æŸ¥å“ªäº›è§„åˆ™å¯¼è‡´äº†è¯¯æŠ¥:")
        fp_rule_counts = {}
        
        # ä¸ºæ¯ä¸ªè¯¯æŠ¥cellæ‰¾åˆ°å¯¹åº”çš„è§„åˆ™
        for fp_cell in fp_cells:
            cell_found = False
            for idx, row in error_df.iterrows():
                rule_cells = json.loads(row['error_cell'])
                if fp_cell in rule_cells:
                    rule_info = f"Rule_{row['rule_id']}: {row['y_pred']} <- {row['best_rule']}"
                    fp_rule_counts[rule_info] = fp_rule_counts.get(rule_info, 0) + 1
                    cell_found = True
                    break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„è§„åˆ™å°±åœæ­¢
        
        # æ˜¾ç¤ºå¯¼è‡´è¯¯æŠ¥æœ€å¤šçš„è§„åˆ™
        if fp_rule_counts:
            sorted_rules = sorted(fp_rule_counts.items(), key=lambda x: x[1], reverse=True)
            print(f"ğŸ“‹ å¯¼è‡´è¯¯æŠ¥æœ€å¤šçš„è§„åˆ™:")
            for rule_info, count in sorted_rules[:5]:
                print(f"  {rule_info}: {count}ä¸ªè¯¯æŠ¥")
            
            # æ˜¾ç¤ºè¯¯æŠ¥åˆ†å¸ƒç»Ÿè®¡
            print(f"\nğŸ“Š è¯¯æŠ¥åˆ†å¸ƒç»Ÿè®¡:")
            total_fp = len(fp_cells)
            covered_fp = sum(fp_rule_counts.values())
            print(f"  æ€»è¯¯æŠ¥æ•°: {total_fp}")
            print(f"  è¢«è§„åˆ™è¦†ç›–çš„è¯¯æŠ¥æ•°: {covered_fp}")
            print(f"  æœªæ‰¾åˆ°æ¥æºçš„è¯¯æŠ¥æ•°: {total_fp - covered_fp}")
        else:
            print("  âš ï¸ æ— æ³•ç¡®å®šè¯¯æŠ¥æ¥æº")
            
        # æ˜¾ç¤ºæ¯ä¸ªè¯¯æŠ¥cellå¯¹åº”çš„è§„åˆ™
        print(f"\nğŸ” è¯¯æŠ¥cellä¸è§„åˆ™å¯¹åº”å…³ç³»:")
        for i, fp_cell in enumerate(fp_cells[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
            cell_found = False
            for idx, row in error_df.iterrows():
                rule_cells = json.loads(row['error_cell'])
                if fp_cell in rule_cells:
                    rule_info = f"Rule_{row['rule_id']}: {row['y_pred']}"
                    print(f"  {i+1}. è¡Œ{fp_cell[0]}, åˆ—{fp_cell[1]} -> {rule_info}")
                    cell_found = True
                    break
            if not cell_found:
                print(f"  {i+1}. è¡Œ{fp_cell[0]}, åˆ—{fp_cell[1]} -> æœªæ‰¾åˆ°å¯¹åº”è§„åˆ™")
        if len(fp_cells) > 10:
            print(f"  ... è¿˜æœ‰ {len(fp_cells)-10} ä¸ªè¯¯æŠ¥cell")
        
        # æ˜¾ç¤ºè¯¯æŠ¥è¯¦æƒ…
        print(f"\nğŸ“‹ è¯¯æŠ¥è¯¦æƒ…:")
        for i, (row_idx, col_name) in enumerate(fp_cells[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
            if row_idx < len(test_clean) and col_name in test_clean.columns:
                clean_val = test_clean.at[row_idx, col_name]
                dirty_val = test_dirty.at[row_idx, col_name]
                # æ­£ç¡®å¤„ç†NaNå€¼æ˜¾ç¤º
                clean_str = str(clean_val) if not pd.isna(clean_val) else 'NaN'
                dirty_str = str(dirty_val) if not pd.isna(dirty_val) else 'NaN'
                print(f"  {i+1}. è¡Œ{row_idx}, åˆ—{col_name}: '{clean_str}' == '{dirty_str}' (å®é™…æ— é”™è¯¯)")
                
                # åˆ†æè¯¯æŠ¥åŸå› ï¼šæ£€æŸ¥è¯¥è¡Œæ˜¯å¦æ»¡è¶³ä»»ä½•è§„åˆ™çš„å‰ææ¡ä»¶
                print(f"     ğŸ” è¯¯æŠ¥åŸå› åˆ†æ:")
                for idx, row in error_df.iterrows():
                    rule_id = row['rule_id']
                    y_pred = row['y_pred']
                    best_rule = row['best_rule']
                    
                    # æ£€æŸ¥è¿™ä¸ªè¯¯æŠ¥æ˜¯å¦ç”±è¿™ä¸ªè§„åˆ™å¼•èµ·
                    rule_cells = json.loads(row['error_cell'])
                    if (row_idx, col_name) in rule_cells:
                        print(f"       - ç”±Rule_{rule_id}å¼•èµ·: {y_pred} <- {best_rule}")
                        
                        # åˆ†æè§„åˆ™å‰ææ¡ä»¶
                        if best_rule:
                            premises = best_rule.split(' ^ ')
                            print(f"         å‰ææ¡ä»¶:")
                            for premise in premises:
                                premise = premise.strip()
                                if premise:
                                    # æ£€æŸ¥è¯¥è¡Œæ˜¯å¦æ»¡è¶³è¿™ä¸ªå‰ææ¡ä»¶
                                    try:
                                        mask = predicate_mask(test_clean, premise)
                                        if mask.iloc[row_idx]:
                                            print(f"           âœ“ {premise} (æ»¡è¶³)")
                                        else:
                                            print(f"           âœ— {premise} (ä¸æ»¡è¶³)")
                                    except:
                                        print(f"           ? {premise} (æ— æ³•è¯„ä¼°)")
                        break
            else:
                print(f"  {i+1}. è¡Œ{row_idx}, åˆ—{col_name}: ç´¢å¼•è¶…å‡ºèŒƒå›´ (test_clean.shape={test_clean.shape})")
        if len(fp_cells) > 10:
            print(f"  ... è¿˜æœ‰ {len(fp_cells)-10} ä¸ªè¯¯æŠ¥")
    
    # æŒ‰åˆ—ç»Ÿè®¡é”™è¯¯åˆ†å¸ƒ
    print(f"\nğŸ“ˆ æŒ‰åˆ—ç»Ÿè®¡é”™è¯¯åˆ†å¸ƒ:")
    col_error_stats = {}
    for row_idx, col_name in real_cells:
        if col_name not in col_error_stats:
            col_error_stats[col_name] = {'total': 0, 'detected': 0, 'missed': 0}
        col_error_stats[col_name]['total'] += 1
        if (row_idx, col_name) in pred_cells:
            col_error_stats[col_name]['detected'] += 1
        else:
            col_error_stats[col_name]['missed'] += 1
    
    # æŒ‰æ£€æµ‹ç‡æ’åº
    sorted_cols = sorted(col_error_stats.items(), 
                        key=lambda x: x[1]['detected']/x[1]['total'] if x[1]['total'] > 0 else 0, 
                        reverse=True)
    
    for col_name, stats in sorted_cols[:10]:  # æ˜¾ç¤ºå‰10åˆ—
        detection_rate = stats['detected'] / stats['total'] if stats['total'] > 0 else 0
        print(f"  {col_name}: {stats['detected']}/{stats['total']} ({detection_rate:.2%})")
    
    # è§„åˆ™è´¨é‡è¯„ä¼°
    print(f"\nğŸ” è§„åˆ™è´¨é‡è¯„ä¼°:")
    for idx, row in error_df.iterrows():
        rule_id = row['rule_id']
        y_pred = row['y_pred']
        best_rule = row['best_rule']
        error_cells = json.loads(row['error_cell'])
        
        # å°†error_cellsè½¬æ¢ä¸ºå…ƒç»„é›†åˆï¼Œä½¿å…¶å¯å“ˆå¸Œ
        error_cells_set = set(tuple(cell) for cell in error_cells)
        
        # è®¡ç®—è¯¥è§„åˆ™çš„ç²¾ç¡®ç‡
        rule_tp = len(error_cells_set & real_cells)
        rule_fp = len(error_cells_set - real_cells)
        rule_precision = rule_tp / (rule_tp + rule_fp) if (rule_tp + rule_fp) > 0 else 0
        
        # è®¡ç®—è¯¥è§„åˆ™çš„å¬å›ç‡
        rule_fn = len(real_cells - error_cells_set)
        rule_recall = rule_tp / (rule_tp + rule_fn) if (rule_tp + rule_fn) > 0 else 0
        
        print(f"  Rule_{rule_id}: {y_pred} <- {best_rule}")
        print(f"    ç²¾ç¡®ç‡: {rule_precision:.3f} (TP={rule_tp}, FP={rule_fp})")
        print(f"    å¬å›ç‡: {rule_recall:.3f} (TP={rule_tp}, FN={rule_fn})")
        print(f"    è¦†ç›–å•å…ƒæ ¼æ•°: {len(error_cells)}")
        print()
    
    with open(os.path.join(data_dir, 'dcr_rule_error_metrics.txt'), 'w', encoding='utf-8') as f:
        f.write(f'Precision: {precision:.4f}\n')
        f.write(f'Recall: {recall:.4f}\n')
        f.write(f'F1: {f1:.4f}\n')
        f.write(f'Accuracy: {accuracy:.4f}\n')
        f.write(f'\né”™è¯¯ç»Ÿè®¡:\n')
        f.write(f'æ€»å•å…ƒæ ¼æ•°: {total_cells}\n')
        f.write(f'å®é™…é”™è¯¯æ•°: {len(real_cells)}\n')
        f.write(f'é¢„æµ‹é”™è¯¯æ•°: {len(pred_cells)}\n')
        f.write(f'çœŸé˜³æ€§(TP): {TP}\n')
        f.write(f'å‡é˜³æ€§(FP): {FP}\n')
        f.write(f'å‡é˜´æ€§(FN): {FN}\n')
        f.write(f'çœŸé˜´æ€§(TN): {TN}\n')
    print('âœ… å·²ä¿å­˜æŸ¥é”™è¯„ä¼°æŒ‡æ ‡åˆ° dcr_rule_error_metrics.txt')


if __name__ == '__main__':
    main() 